{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Önsöz\n",
    "\n",
    "Merhaba arkadaşlar, bu noktaya kadar \"Least Squares Method\"u 0'dan türettik fakat yaptığımız her şey kağıt üstünde formülizasyondan ibaretti.\n",
    "Bu noktaya kadarki kısım çok kıymetli olsa da en nihayetinde \"Least Squares Method\" bilgisayarda çalışması gereken bir algoritma. O yüzden bu ufak\n",
    "egzersizde \"Least Squares Method\"un kapalı formda çözümünü koda dökeceğiz.\n",
    "\n",
    "**Anahtar Kelimeler:** *Least Squares Method, Linear Regression, Closed Form Solution*\n",
    "\n",
    "### İşleyiş\n",
    "\n",
    "Bu \"notebook\"da bazı kısımları sizlerin doldurması için boş bıraktım. Sadece bu kısımları doldurun, tüm \"cell\"leri yukarıdan aşağı çalıştırın ve eğlenmenize bakın :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basit bir örnek ile başlayalım, README.md dosyasındaki örneği hatırlayın, 2 boyutlu koordinat sisteminde noktalar var ve biz bu noktalara uygun\n",
    "fonksiyonu bulmaya çalışıyoruz. Gelin aynı örneği kodlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Creation\n",
    "\n",
    "# Bu kısımda bize uygun bir veri seti oluşturuyoruz. Burada sizin müdahele etmenizi gerektiren bir kısım yok fakat yine de anlamak için\n",
    "# inceleyebilirsiniz.\n",
    "\n",
    "x_range = (-10, 10) # x değerlerinin alabileceği aralık\n",
    "n = 100 # veri setindeki örnek sayısı\n",
    "\n",
    "# Şimdi noktalarımızın takip etmesini istediğimiz 2 boyutlu lineer fonksiyonu tanımlayalım\n",
    "m = 2 # eğim\n",
    "b = 5 # y eksenini kestiği nokta\n",
    "\n",
    "# Şimdi x için tanımladığımız aralıkta n adet rasgele sayı üretelim\n",
    "x = np.random.uniform(x_range[0], x_range[1], n)\n",
    "\n",
    "# Şimdi y değerlerini hesaplayalım\n",
    "y = m * x + b # Bildiğiniz doğru denklemi\n",
    "\n",
    "# Bu noktada (x, y) şeklinde noktaları plot edersek kusursuz bir doğru elde ederiz\n",
    "plt.plot(x, y, 'o')\n",
    "plt.title(\"Gürültü eklenmemiş veri seti\")\n",
    "plt.show()\n",
    "\n",
    "# Fakat bu veri seti oldukça basit ve gerçek hayattaki veri setlerinin aksine kusursuz bir doğru elde ettik.\n",
    "# O zaman bu veri setine biraz gürültü ekleyelim. Bunun için y değerlerine \"Gaussian Distribution\" kullanarak gürültü ekleyeceğiz. (Bknz: https://en.wikipedia.org/wiki/Normal_distribution)\n",
    "\n",
    "y_noise = np.random.normal(0, 5, n) # ortalama 0, standart sapma 5 olan Gaussian Distribution'dan n adet rasgele sayı üretiyoruz\n",
    "y = y + y_noise # y değerlerine gürültüyü ekliyoruz\n",
    "\n",
    "# Şimdi veri setimizi tekrar plot edelim\n",
    "plt.plot(x, y, 'o')\n",
    "plt.title(\"Gürültü eklenmiş veri seti\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu kısım tamamen ne olduğu bildiğimiz bir fonksiyonu nasıl çizdiririz bununla alakalı, least squares ile alakalı değil. Genel bir bilgi.\n",
    "\n",
    "# Genelde herhangi bir fonksiyonu plot etmek istediğimizde belli bir aralıkta yüksek miktarda eşit aralıklı nokta üretiriz.\n",
    "# Aşama aşama mantığı göstermemiz gerekirse nokta sayısı n = 2, 5, 10, 20, 50, 100 ve 500 için plot edelim.\n",
    "\n",
    "# Öncelikle x değerlerini üretelim\n",
    "x_plot = [ np.linspace(x_range[0], x_range[1], n_plot) for n_plot in [2, 5, 10, 20, 50, 100, 500] ]\n",
    "\n",
    "# Şimdi y değerlerini hesaplayalım\n",
    "y_plot = [ m * x + b for x in x_plot ]\n",
    "\n",
    "# Şimdi plot edelim\n",
    "for i in range(len(x_plot)):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.scatter(x_plot[i], y_plot[i], s=2)\n",
    "    plt.title(\"n = \" + str(len(x_plot[i])))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü gibi çizdirmek istediğimiz plot üstünde ne kadar fazla noktayı çizersek o kadar sanki devamlı bir fonksiyon gibi gözüken plot elde ederiz. Bu genel bir tekniktir, \"notebook\"un kalanında da bolca kullanacağımız için göstermiş olalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datayı kendi seçtiğimiz ama ilerleyen kısımda bilmediğimizi varsaydığımız bir doğruya göre üretmiştik, şimdi o doğruyu çizelim.\n",
    "# Çizdiğimiz bu doğru \"least squares method\" ile bulmaya çalışacağımız doğru olacak.\n",
    "\n",
    "plt.scatter(x, y)\n",
    "x_plot = np.linspace(x_range[0], x_range[1], 1000)\n",
    "y_plot = m * x_plot + b\n",
    "\n",
    "plt.scatter(x_plot, y_plot, color='red', s=0.5)\n",
    "\n",
    "plt.title('Datayı ifade eden gerçek doğru ve ürettiğimiz data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buraya kadarki kısım bir direkt olarak \"Least Squares Method\"un uygulanması ile alakalı değildi, sadece işin görselleştirme ve datasetleri tanımlama kısmıydı, şimdi asıl kısıma geçelim.\n",
    "\n",
    "### Least Squares Method\n",
    "\n",
    "Problemimizi kısaca özetleyelim, herhangi bir $\\textbf{w} \\in \\mathbb{R}^D$ parametre vektörü için, $\\textbf{X}$ matrisindeki her bir elemandan elde ettiğimiz tahminleri $\\hat{\\textbf{Y}} = \\textbf{X}\\textbf{w}$ olarak göstermiştik.\n",
    "Denediğimiz herhangi bir $\\textbf{w}$ için, tahminlerin gerçeğe ne kadar yakın olduğunu görmek adına da bir de hata fonksiyonu tanımlamıştık, bu fonksiyonu $\\textbf{w}$'nin bir fonksiyonu olarak yazarsak:\n",
    "\n",
    "$E: \\mathbb{R}^D \\rightarrow \\mathbb{R}, \\quad E(\\textbf{w}) = \\sum_{i=1}^N (\\textbf{Y}_i - \\hat{\\textbf{Y}}_i)^2 = (\\textbf{Y} - \\hat{\\textbf{Y}})^T(\\textbf{Y} - \\hat{\\textbf{Y}}) = (\\textbf{Y} - \\textbf{X}\\textbf{w})^T(\\textbf{Y} - \\textbf{X}\\textbf{w})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gelin bu hata fonksiyonunu bir python fonksiyonu olarak tanımlayalım.\n",
    "\n",
    "def E(w: np.ndarray, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    \"\"\" Bu fonksiyon parametre olarak aldığı w ağırlık vektörü için\n",
    "    ortalama hata kareler toplamını (mean squared error) hesaplayıp geri döndürsün.\n",
    "\n",
    "    Önemli not 1: For veya while döngüsü kullanmadan, sadece matris işlemleri ile bu fonksiyonu yazın.\n",
    "\n",
    "    Args:\n",
    "        w (numpy.ndarray): Ağırlık vektörü. Boyutu D x 1.\n",
    "\n",
    "    Returns:\n",
    "        float: Hata değeri.\n",
    "    \"\"\"\n",
    "\n",
    "    err = 0.0 # Hesaplandıktan sonra döndürülecek hata değeri\n",
    "\n",
    "    # TODO: Hata değerini hesaplayın ve err değişkenine atayın.\n",
    "\n",
    "    #################################################\n",
    "    ########## KODUNUZU BURAYA YAZINIZ ##############\n",
    "    #################################################\n",
    "\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. Test\")\n",
    "print(\"Hatayı doğru hesaplayabiliyor muyuz?\")\n",
    "\n",
    "test_X = np.array([[ 0.04091918, -1.00218746], [ 0.74082435, -0.51321357], [-0.22859992, -0.99434937]])\n",
    "test_Y = np.array([[-2.56233366], [-0.19102776], [ 2.41261542]])\n",
    "test_ws = [ np.array([[1.0, 2.0]]).T, np.array([[3.0, 4.0]]).T, np.array([[5.0, 6.0]]).T, np.array([[7.0, 8.0]]).T, np.array([[9.0, 10.0]]).T ]\n",
    "\n",
    "expected_errors = [ 21.80370359, 51.94926291, 101.86640895, 171.55514171, 261.01546118 ]\n",
    "\n",
    "for i in range(len(test_ws)):\n",
    "    print(\"Test\", i+1, \":\", end=\" \")\n",
    "    error = E(test_ws[i], test_X, test_Y)\n",
    "    if np.isclose(error, expected_errors[i]):\n",
    "        print(\"BAŞARILI\")\n",
    "    else:\n",
    "        print(\"ÇUVALLADI: Beklenen\", expected_errors[i], \"elde edilen\", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eklememiz Gereken Ufak Bir Detay:\n",
    "\n",
    "Şimdiye kadar herhangi bir $x_i \\in \\mathbb{R}^{D \\times 1}$ verisi için karşılık gelen $\\hat{y}_i$ değerini tahmin etmek için $\\hat{y}_i = x_i^Tw$ ifadesini kullandık. (X ve Y matrislerini nasıl tanımladığımızı düşününün, X'in tek bir satırı için gösterim bu olur.)\n",
    "\n",
    "Bu gösterim aslında birçok açıdan doğru, ama bazı özel durumlar için biraz daha açıklama gerektiriyor. Mesela bizim doğru bulma örneğimizi düşünelim.\n",
    "Bulmak istediğimiz doğru denklemi $y = m \\times x + b$ formatında (bildiğimiz 2 boyutlu doğru) yani sadece 1 adet $x$ değeri için karşılık gelen bir $y$ değeri var.\n",
    "O zaman bunları matris formuna getirecek olursak $D=1$ olarak modellememiz gerekir ve $\\textbf{X} \\in \\mathbb{R}^{N \\times 1}, \\textbf{Y} \\in \\mathbb{N}, \\textbf{w} \\in \\mathbb{R}^{1 \\times 1}$ olur.\n",
    "Fakat burada çok büyük bir problem var, $\\textbf{w}$ bir skaler! Yani ortada bilinmeyen sadece tek bir parametre var, ama $y = m \\times x + b$ denkleminde bulmamız gereken 2 parametre (m ve b) var!\n",
    "Demek ki bir şeyleri yanlış yapıyoruz.\n",
    "\n",
    "Aslında tüm problem konunun en başında yaptığımız bir __basitleştirmeden__ kaynaklı, çok boyutlu senaryoya dönersek şunu demiştik:\n",
    "\n",
    "Tek bir $\\textbf{x} \\in \\mathbb{R}^{D}$ vektörü ve parametre vektörü $\\textbf{w} \\in \\mathbb{R}^{D}$ için $\\hat{y} = \\textbf{x}^T\\textbf{w} = \\sum_{i=1}^D \\textbf{x}_i \\times \\textbf{w}_i$ ifadesini kullanarak $\\hat{y}$ değerini tahmin edebiliriz.\n",
    "\n",
    "Bu ifadede __tüm terimler__ $x$ __lere bağlı__! Ama $y = m \\times x + b$ denkleminde $b$, $x$'e bağlı değil, yani bizim modelimiz bu denklemi ifade edemiyor!!!\n",
    "\n",
    "İşte burada kendi problemimizdeki $x$ leri farklı bir şey olarak görmeye ihtiyacımız var, başta demiştik ki $\\textbf{x}$ vektörü herhangi obje tipi ile ilgili sayısal veriler barındırır, mesela arsa alanı, ağaç sayısı, en, boy gibi demiştik. Bu durumda ne kadar ölçümümüz varsa $\\textbf{x}$ o kadar boyutlu oluyordu. Yani bizim ölçtüğümüz özellik sayısı $D$ ye eşitti, ama bu bizi belli şeyleri yapmaktan alıkoyuyor.\n",
    "\n",
    "O zaman şöyle düşünsek nasıl olur $\\textbf{x}$ sadece yaptığımız ölçümler olmasın, içine alaksız şeyler de koyabilelim, eklediğimiz her yeni şey için de $D$'yi ona göre arttıralım ve bu her yeni şeye de karşılık gelen bir $\\textbf{w}_i$ değeri olsun. Örneğin bir arsayı ifade eden $\\textbf{x}$ vektörüne yeni bir eleman ekleyelim $1$ bildiğiniz dümdüz $1$. Yani yeni $\\textbf{x}$ :\n",
    "\n",
    "$\\textbf{x}_{yeni} = [ \\textbf{x}_1 ,\\textbf{x}_2, ..., \\textbf{x}_D, 1 ]^T $ şeklinde bir vektör olacak, bu bize ne kazandırır? Artık tahmin edilen $\\hat{y}$ :\n",
    "\n",
    "$\\hat{y} = \\textbf{x}_{yeni}^T\\textbf{w}_{yeni} = \\textbf{x}_1 \\times \\textbf{w}_1 + \\textbf{x}_2 \\times \\textbf{w}_2 + ... + \\textbf{x}_D \\times \\textbf{w}_{D} + 1 \\times \\textbf{w}_{D+1}$\n",
    "\n",
    "$= \\textbf{x}_1 \\times \\textbf{w}_1 + \\textbf{x}_2 \\times \\textbf{w}_2 + ... + \\textbf{x}_D \\times \\textbf{w}_{D} + \\textbf{w}_{yeni \\space D+1}$\n",
    "\n",
    "Yeni eklenen $\\textbf{w}_{yeni \\space D+1}$ parametresi orijinal $\\textbf{x}$ e bağlı değil!!! Yani yeni modelimiz artık $y = m \\times x + b$ denklemini de ifade edebilir!\n",
    "\n",
    "Bu yeni tekniği daha da genelleştirebiliriz, örneğin $x \\in \\mathbb{R}$ sayısının $P$ cinsinden bir polinomuna bağlı bir y öğrenmek istiyoruz, yani $y = a_0 + a_1 \\times x + a_2 \\times x^2 + ... + a_P \\times x^P$ denklemi için $\\textbf{x} \\in \\mathbb{R}^{P+1}$ ve $\\textbf{w} \\in \\mathbb{R}^{P+1}$ olur. Bu durumda $\\textbf{x}$ vektörümüzü şöyle tanımlayabiliriz:\n",
    "\n",
    "$\\textbf{x} = [1, x, x^2, ..., x^P]^T$\n",
    "\n",
    "Buna karşılık gelen $\\textbf{w}$ vektörü de:\n",
    "\n",
    "$\\textbf{w} = [a_0, a_1, a_2, ..., a_P]^T$\n",
    "\n",
    "Yani anlayacağınız $\\textbf{x}$ e lineer olarak bağlı olmayan fonksiyonları bile öğrenmemiz aslında mümkün, tek gereken ihtiyacımız olan her türlü terimi $\\textbf{x}$ vektörüne eklemek ve ona karşılık gelen $\\textbf{w}$ parametrelerini öğrenmek.\n",
    "\n",
    "### Bizim Probleme Dönersek\n",
    "\n",
    "$y = m \\times x + b$ formunda bir fonksiyonu öğrenmemiz için $\\textbf{x} = [x, 1]^T$ ve $\\textbf{w} = [m, b]^T$ olur. Yani $\\textbf{x}$ vektörümüzü ölçümlerimizden oluşan bir vektör ve $1$'den oluşan bir vektörün birleşimi olarak düşünebiliriz. $\\textbf{w}$ vektörümüz ise $m$ ve $b$ parametrelerimizi içeriyor. Artık problemi çözmek için gereken her şey elimizde!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu kısımda başta yarattığımız x ve y değerlerini istediğimiz formata dönüştürelim.\n",
    "\n",
    "# Hatırlayın sadece tek bir ölçümümüz var, noktamızın x eksenindeki konumu, buna göre y'yi bulmak istiyoruz, bunun için x'e bağlı olmayan ikinci bir parametre öğrenmek istiyoruz.\n",
    "x = x.reshape(-1, 1) # Öncelikle x değerlerini N x 1 boyutlu bir matrise dönüştürüyoruz\n",
    "ones = np.ones((n, 1)) # N x 1 boyutlu 1'lerden oluşan bir matris oluşturuyoruz\n",
    "\n",
    "# Şimdi eğer bu iki matrisi yan yana birleştirirsek N x 2 boyutlu bir matris elde ederiz\n",
    "# Bu matrisin her bir satırında x değerimiz ve 1 değeri olacak yani önceden tartıştığımız formüldeki x ve 1 değerleri\n",
    "X = np.concatenate((x, ones), axis=1)\n",
    "\n",
    "# Şimdi de y değerlerini N x 1 boyutlu bir matrise dönüştürüyoruz\n",
    "Y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2. Test\")\n",
    "print(\"Matrisleri doğru yarattık mı ve hata fonksiyonu bu örneğimizde de doğru çalışıyor mu?\")\n",
    "\n",
    "print()\n",
    "print(\"Yarattığımız yeni X'in ilk 5 satırı:\")\n",
    "print(X[:5, :])\n",
    "\n",
    "print()\n",
    "print(\"Yarattığımız yeni Y'in ilk 5 satırı:\")\n",
    "print(Y[:5, :])\n",
    "\n",
    "test_ws = [ np.array([[1.0, 2.0]]).T, np.array([[3.0, 4.0]]).T, np.array([[5.0, 6.0]]).T, np.array([[7.0, 8.0]]).T, np.array([[9.0, 10.0]]).T ]\n",
    "\n",
    "expected_errors = [ 5336.84446228, 6626.14500242, 36082.55356589, 93706.07015268, 179496.69476279 ]\n",
    "\n",
    "print()\n",
    "\n",
    "for i in range(len(test_ws)):\n",
    "    print(\"Test\", i+1, \":\", end=\" \")\n",
    "    error = E(test_ws[i], X, Y)\n",
    "    if np.isclose(error, expected_errors[i]):\n",
    "        print(\"BAŞARILI\")\n",
    "    else:\n",
    "        print(\"ÇUVALLADI: Beklenen\", expected_errors[i], \"elde edilen\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X ve Y matrislerini alıp en iyi w'yu döndüren fonksiyou yazalım.\n",
    "\n",
    "def find_best_w(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Bu fonksiyon parametre olarak aldığı X ve Y matrislerini kullanarak\n",
    "    en iyi w değerini bulup geri döndürür.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): X matrisi. Boyutu N x D.\n",
    "        Y (numpy.ndarray): Y matrisi. Boyutu N x 1.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: En iyi w değeri. Boyutu D x 1.\n",
    "    \"\"\"\n",
    "\n",
    "    w = np.zeros((X.shape[1], 1)) # En başta w değerimizi 0'lar ile başlatalım.\n",
    "\n",
    "    # TODO: w değerini bulun ve w değişkenine atayın.\n",
    "\n",
    "    #################################################\n",
    "    ########## KODUNUZU BURAYA YAZINIZ ##############\n",
    "    #################################################\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"3. Test\")\n",
    "print(\"Optimal w'yu bulabiliyor muyuz?\")\n",
    "\n",
    "w = find_best_w(X, Y) # En iyi w değerini bulalım\n",
    "err = E(w, X, Y) # Bulduğumuz w değeri ile hatayı hesaplayalım\n",
    "\n",
    "print()\n",
    "print(\"Bulduğumuz w değeri:\")\n",
    "print(w)\n",
    "\n",
    "print()\n",
    "print(\"Gerçek w değeri:\")\n",
    "print(np.array([[2.0], [5.0]])) # m = 2, b = 5 yani gerçek w değerimiz bu\n",
    "\n",
    "print()\n",
    "print(\"Bulduğumuz w değeri ile elde ettiğimiz hata:\")\n",
    "print(err)\n",
    "\n",
    "print()\n",
    "print(\"Gerçek w değeri ile elde etmemiz gereken hata:\")\n",
    "print(2016.46140992)\n",
    "\n",
    "print()\n",
    "print(\"Öğrendiğimiz fonksiyonun grafiği:\")\n",
    "\n",
    "x_plot = np.linspace(-10, 10, 1000) # -10 ile 10 arasında 1000 tane x değeri oluşturalım\n",
    "y_plot_pred = w[0] * x_plot + w[1] # Bu x değerlerine karşılık gelen y değerlerini hesaplayalım\n",
    "y_plot_real = 2 * x_plot + 5 # Gerçek y değerlerini hesaplayalım\n",
    "\n",
    "plt.scatter(X[:, 0], Y[:, 0], label=\"Veri\", s=3) # Verileri çizelim\n",
    "plt.scatter(x_plot, y_plot_pred, label=\"Öğrenilen fonksiyon\", s=0.5) # Öğrenilen fonksiyonun grafiğini çizelim\n",
    "plt.scatter(x_plot, y_plot_real, color=\"red\", label=\"Gerçek fonksiyon\", s=0.5) # Gerçek fonksiyonun grafiğini çizelim\n",
    "plt.legend() # Grafiğin sağ üstünde açıklamaları gösterelim\n",
    "plt.show() # Grafiği gösterelim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gördüğünüz gibi $\\textbf{w}$ yu kusursuz bir şekilde tahmin edemedik, ama bu çok normal. En nihayetinde veriyi oluştururken biraz gürültü eklemiştik, bu gürültüyü de modelimiz öğrenmiş oldu. Ama yine de modelimiz veriyi oldukça iyi öğrenmiş, yani veriyi oluşturan gerçek fonksiyonu oldukça iyi yakalamış. Bu da kabul edilmesi gereken önemli bir nokta, herhangi bir machine learning modeli verisi ne kadar iyiyse en fazla o kadar iyi olabilir ama daha iyi olamaz. Çok gürültülü bir veri seti ile en iyi machine learning modeli bile çuvallayacaktır, gerçek hayatta gürültüden tamamen kurtulmak mümkün olmasa da en önemli işlerden biri veriyi mümkün olduğunca gürültüden arındırmaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oldukça Eğlenceli Yeni Bir Örnek\n",
    "\n",
    "Şimdi bu öğrendiklerimizi çok daha ilginç bir örnekte kullanalım, mesela veri setini bir sinüs fonksiyonu kullanarak yaratsak ne olur?\n",
    "\n",
    "Hemen asıl işe koyulalım, yine aynı şekilde belli bir aralıkta rastgele x değerleri üreteceğiz sonra sin(x) fonksiyonunu kullanarak y değerlerimizi üreteceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeni veri setinin üretimi\n",
    "\n",
    "x_range = (-5, 5) # x değerlerinin alabileceği aralık\n",
    "n = 300 # 100 adet ölçüm\n",
    "\n",
    "x = np.linspace(x_range[0], x_range[1], n) # x değerlerini üretelim\n",
    "y = np.sin(x) # y değerlerini üretelim\n",
    "\n",
    "plt.scatter(x, y, s=1) # x ve y değerlerini nokta nokta çizdirelim\n",
    "plt.title(\"Veri Setimizi Oluşturan Noktalar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu sefer işin güzelliğini bozmamak için gürültü eklemiyoruz ama yine de biraz daha ilginç bir veri seti oluşturmuş olduk.\n",
    "\n",
    "Asıl sebebi bazılarınız fark etmiş olacak ama fark etmeyenler için asıl sürprizi sona saklayalım, şimdi elimizde lineer ile uzaktan yakından alakası olmayan bir fonksiyon var, $y = m \\times x + b$ gibi basit bir formda hiç değil.\n",
    "\n",
    "Peki sizce bu sefer $\\textbf{x}$ vektörünü nasıl oluşturmak mantıklı? Az önce yaptığımız gibi yanına sadece 1 ekleyerek mi? Önce bunu deneyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu kısımda başta yarattığımız x ve y değerlerini istediğimiz formata dönüştürelim.\n",
    "\n",
    "# Hatırlayın sadece tek bir ölçümümüz var, noktamızın x eksenindeki konumu, buna göre y'yi bulmak istiyoruz, bunun için x'e bağlı olmayan ikinci bir parametre öğrenmek istiyoruz.\n",
    "x = x.reshape(-1, 1) # Öncelikle x değerlerini N x 1 boyutlu bir matrise dönüştürüyoruz\n",
    "ones = np.ones((n, 1)) # N x 1 boyutlu 1'lerden oluşan bir matris oluşturuyoruz\n",
    "\n",
    "# Şimdi eğer bu iki matrisi yan yana birleştirirsek N x 2 boyutlu bir matris elde ederiz\n",
    "# Bu matrisin her bir satırında x değerimiz ve 1 değeri olacak yani önceden tartıştığımız formüldeki x ve 1 değerleri\n",
    "X = np.concatenate((x, ones), axis=1)\n",
    "\n",
    "# Şimdi de y değerlerini N x 1 boyutlu bir matrise dönüştürüyoruz\n",
    "Y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"4. Test\")\n",
    "print(\"Optimal w'yu bulabiliyor muyuz?\")\n",
    "\n",
    "w = find_best_w(X, Y) # En iyi w değerini bulalım\n",
    "err = E(w, X, Y) # Bulduğumuz w değeri ile hatayı hesaplayalım\n",
    "\n",
    "print()\n",
    "print(\"Bulduğumuz w değeri:\")\n",
    "print(w)\n",
    "\n",
    "print()\n",
    "print(\"Öğrendiğimiz fonksiyonun grafiği:\")\n",
    "\n",
    "x_plot = np.linspace(-5, 5, 1000) # -10 ile 10 arasında 1000 tane x değeri oluşturalım\n",
    "y_plot_pred = w[0] * x_plot + w[1] # Bu x değerlerine karşılık gelen y değerlerini hesaplayalım\n",
    "y_plot_real = np.sin(x_plot) # Gerçek y değerlerini hesaplayalım\n",
    "\n",
    "plt.scatter(x, y, label=\"Veri\", s=3) # Verileri çizelim\n",
    "plt.scatter(x_plot, y_plot_pred, label=\"Öğrenilen fonksiyon\", s=0.5) # Öğrenilen fonksiyonun grafiğini çizelim\n",
    "plt.scatter(x_plot, y_plot_real, label=\"Gerçek fonksiyon\", s=0.5) # Gerçek fonksiyonun grafiğini çizelim\n",
    "plt.legend() # Grafiğin sağ üstünde açıklamaları gösterelim\n",
    "plt.show() # Grafiği gösterelim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gördüğünüz gibi bu sefer hiç de iyi bir sonuç elde edemedik, hatta veriyi oluşturan fonksiyonu hiç yakalayamadık bile. Peki neden? Çünkü $\\textbf{x}$ vektörümüz artık $y = m \\times x + b$ formunda bir fonksiyonu ifade etmiyor, peki önceden bahsettiğimiz polinom örneğindeki gibi bir $P$ sayısı belirleyip $P$ dereceden bir polinom ile öğrenmeyi denesek? Hemen deneyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu kısımda başta yarattığımız x ve y değerlerini istediğimiz formata dönüştürelim.\n",
    "\n",
    "# Hatırlayın sadece tek bir ölçümümüz var, noktamızın x eksenindeki konumu, buna göre y'yi bulmak istiyoruz\n",
    "# Bu sefer x'in 0'dan P'ye kadar kuvvetlerini vektörümüze eklemek istiyoruz ki polinom katsayılarını öğrenebilelim\n",
    "\n",
    "x = x.reshape(-1, 1) # Öncelikle x değerlerini N x 1 boyutlu bir matrise dönüştürüyoruz\n",
    "\n",
    "# Şimdi x'in kuvvetlerinden oluşan bir liste oluşturalım, bunun için önce polinom dereceği P'yi belirleyelim\n",
    "P = 5\n",
    "\n",
    "powers = [ x ** i for i in range(0, P + 1) ] # x'in 0'dan P'ye kadar kuvvetlerini alalım\n",
    "\n",
    "# Şimdi de hepsini birleştirip N x (P + 1) boyutlu bir matris elde edelim\n",
    "X = np.concatenate(powers, axis=1)\n",
    "\n",
    "# Şimdi de y değerlerini N x 1 boyutlu bir matrise dönüştürüyoruz\n",
    "Y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"5. Test\")\n",
    "print(\"Optimal w'yu bulabiliyor muyuz?\")\n",
    "\n",
    "w = find_best_w(X, Y) # En iyi w değerini bulalım\n",
    "err = E(w, X, Y) # Bulduğumuz w değeri ile hatayı hesaplayalım\n",
    "\n",
    "print()\n",
    "print(\"Bulduğumuz w değeri:\")\n",
    "print(w)\n",
    "\n",
    "print()\n",
    "print(\"Olması gereken w değeri:\")\n",
    "print(\"\"\"[[-1.85467960e-14]\n",
    " [ 8.64102413e-01]\n",
    " [ 6.53036653e-15]\n",
    " [-1.13925341e-01]\n",
    " [-2.87991202e-16]\n",
    " [ 2.93910939e-03]]\"\"\")\n",
    "\n",
    "print()\n",
    "print(\"Öğrendiğimiz fonksiyonun grafiği:\")\n",
    "\n",
    "x_plot = np.linspace(-5, 5, 1000) # -10 ile 10 arasında 1000 tane x değeri oluşturalım\n",
    "# Şimdi de bu x değerlerinin kuvvetlerinden oluşan bir matris oluşturalım (Öğrendiğimzi fonksiyon girdi alarak bunu almak zorunda)\n",
    "x_plot_powers = np.array([ x_plot.reshape(1000, 1) ** i for i in range(0, P + 1) ])\n",
    "x_plot_matrix = np.concatenate(x_plot_powers, axis=1) # Bu matrisi N x (P + 1) boyutlu bir matrise dönüştürelim\n",
    "\n",
    "y_plot_pred = x_plot_matrix @ w # Bu x değerlerine karşılık gelen y değerlerini hesaplayalım (@ burada matris çarpımı demek, unutmayın bu matris çarpımı zaten bir tahmin ettiğimiz y'leri veriyor)\n",
    "# Bu sefer matris çarpımı ile hesapladığımız için y_plot_pred N x 1 boyutlu bir matris olacak, plot etmek için bunu düz bir vektöre çevirelim\n",
    "y_plot_pred = y_plot_pred.reshape(-1)\n",
    "\n",
    "y_plot_real = np.sin(x_plot) # Gerçek y değerlerini hesaplayalım\n",
    "\n",
    "plt.scatter(x, y, label=\"Veri\", s=5) # Verileri çizelim\n",
    "plt.scatter(x_plot, y_plot_pred, label=\"Öğrenilen fonksiyon\", s=0.5) # Öğrenilen fonksiyonun grafiğini çizelim\n",
    "plt.scatter(x_plot, y_plot_real, label=\"Gerçek fonksiyon\", s=0.5) # Gerçek fonksiyonun grafiğini çizelim\n",
    "plt.legend() # Grafiğin sağ üstünde açıklamaları gösterelim\n",
    "plt.show() # Grafiği gösterelim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etkileyici Son\n",
    "\n",
    "Bu sefer öğrendiğimiz bu fonksiyon gerçeğe oldukça benziyor, peki neden? Taylor açılımını hatırlayalım:\n",
    "\n",
    "$sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + ...$\n",
    "\n",
    "Yani aslında sin(x) fonksiyonu bir polinom ile ifade edilebilir, hatta bu polinomun derecesini arttırdıkça sin(x) fonksiyonuna daha da yaklaşabiliriz. İşte bu yüzden $\\textbf{x}$ vektörümüzü $P$ dereceden bir polinom ile oluşturduğumuzda sin(x) fonksiyonunu oldukça iyi yakaladık.\n",
    "\n",
    "Hatta ve hatta :)\n",
    "\n",
    "Sırası ile $x^0$ yani $1$ e karşılık gelen katsayı $-1.85467960 \\times 10^{-14} \\sim 0$\n",
    "\n",
    "$x^1$ yani $x$ e karşılık gelen katsayı $8.64102413 \\times 10^{-01} \\sim 0.864$\n",
    "\n",
    "$x^2$ ye karşılık gelen katsayı $6.53036653 \\times 10^{-15} \\sim 0$\n",
    "\n",
    "$x^3$ ye karşılık gelen katsayı $-1.13925341 \\times 10^{-01} \\sim -0.113$\n",
    "\n",
    "$x^4$ ye karşılık gelen katsayı $-2.87991202 \\times 10^{-16} \\sim 0$\n",
    "\n",
    "$x^5$ ye karşılık gelen katsayı $2.93910939 \\times 10^{-03} \\sim 0.00293$\n",
    "\n",
    "şeklinde.\n",
    "\n",
    "Peki Taylor açılımında bunlara denk gelen katsayılar neydi?\n",
    "\n",
    "$ 0, 1, 0, -\\frac{1}{3!}, 0, \\frac{1}{5!}$\n",
    "\n",
    "Yani:\n",
    "\n",
    "$ 0, 1, 0, -0.1666, 0, 0.0083$\n",
    "\n",
    "Elbette veri sayısını arttırdıkça bu katsayılar daha da yaklaşacaktır (Deneyebilirsiniz).\n",
    "Veya daha fazla polinom derecesi kullanarak da daha iyi sonuçlar elde edebiliriz. (Deneyebilirsiniz)\n",
    "\n",
    "#### Kendinize iyi bakın, görüşmek üzere :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
